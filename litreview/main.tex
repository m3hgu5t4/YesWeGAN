\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[style=science]{biblatex}

\title{GAN Literature Review}
\author{Ismael Carlosse \and Charlie Hart \and Jowita Khider \and Patrick Luo}
\date{January 2019}

\begin{document}

\maketitle

\section{Introduction}
\paragraph{}
Since their inception in 2014 by Goodfellow et al, the GAN framework has been applied to countless projects such as image recognition, generation and pixel-to-pixel translation, turning one image into another. However, this framework is still under-explored in many fields, such as sound, text or other data generation. In our project, tentatively named Yes We GAN, we hope to show that the applications of GANs are wide and varied, and that any data that can conceivably be collected on this president can, and should, be used in training and optimising a neural network. 
\paragraph{}
When researching the uses of GANs we found that many of their current implementations revolve around images and image-to-image operations – many implementations such as PyTorch and Pix2pix are optimized around this use case. Whilst these are extremely useful, we feel that there could be a few use cases revolving around text - given the fact that GANs are data-agnostic. Whilst their inherent determinism and tendency to produce noise makes them more suited to continuous data such as images and sound rather than things like language processing, there is no reason they could not be extended to any information representable on a computer such as text.

\section{Literature Review}
\subsection{Introduction}
In order to gain a better understanding of GANs we annotated a wide breadth of literature. Initially, we looked at works discussing the fundamentals of GANs and what they are. This gave us an understanding of how neural networks function. With this knowledge, we transitioned into looking at how we could make our own GANs before finally looking at potential uses of GANs and how this applied to what we wanted to make. We hope to eventually use this knowledge to create our own novel use case for GANs.

\subsection{The Articles}
\paragraph{}
The first work we looked at was an article\cite{whatisgan} describing what a GAN was. It was written by Hui – a software architect at InnoTrekker and also one of the top writers on artificial intelligence. Hui manages to give an impressively in-depth overview of Generative Adversarial Networks in a relatively short article. He explains what a GAN is in a concise manner and then proceeds to goes into detail on the maths behind them. Unlike other articles, the explanation of GANs was clear but the maths is quite complicated and requires multiple readings to fully grasp. Hui aims this article at people with at least a basic understanding of machine learning. He is extremely enthusiastic about GANs and their potential, but the article remains unbiased. This article would benefit anyone interested in machine learning in general. Unfortunately, this article used some relatively complicated mathematics that we found difficult to comprehend. Furthermore, it did not teach us much about the programming of GANs. 

\paragraph{}
Next, we wanted to get a deeper understanding of the fundamental workings of neural networks. We used this\cite{video} video series by 3blue1brown, an educational YouTube channel specialising in mathematical and computer science-oriented videos. Their experience in education has given them a broad insight on many topics and they pride themselves on teaching in simple ways with visualisations of problems. In this 4-part video series, the channel explains what a neural network is and how they function before delving into the mathematics and calculus required to understand them in more detail. The topic is presented in an engaging way and is ideal for somebody with only a surface-level or even no understanding of the field of neural networks and can help to bridge the gap to more rigorous papers or complex implementations. The source is especially useful for its more intuitive explanations of the concepts at play in machine learning, which are often neglected in other educational material, and focus on understanding on a conceptual as well as a mathematical level. However, to somebody more involved in the study or who already understands neural networking, there is less to gain from this video. Overall, we have found this video very helpful in beginning to implement our own neural network, and it has helped to build the foundational understanding we will need to progress to higher levels of study.

\paragraph{}
Now that we had a good grasp on how GANs function, we were ready to start developing our own. We found a tutorial\cite{blitz} which explained how to use the pytorch library for python and taught us the its basic concepts and features. The source introduced us to the library and got us to a high enough level of understanding to be able to effectively use the library in a short amount of time. It is written by a machine learning researcher and is hosted on the library’s website, suggesting that the tutorial is credible. This article is intended for people who are interested in, or researching, machine learning, and are looking for a library to use for their project, and would be useful to our project, as it helps us to understand how to use the library and begin working on a neural network.

\paragraph{}
As we started to explore programming our GAN, we needed inspiration on what to implement. so we decided to find some for ideas. In this article\cite{chairs}, Dosovitskiy et al. created a convolutional neural network that with the use of supervised training, which can not only interpolate between given 3D chair models but create its own. The author used their own data gathered through creating unique images and using their neural network to activate various transformations on given images. Their research concentrated on how a neural network can show correspondences in different images of a database, proving they are capable of generalising characteristics. This then minimised the ‘Euclidean reconstruction error’ of generated images, showing the produced data is not just copies from images within the dataset. As this article was also published in the CVPR2015 paper (Conference on Computer Vision and Pattern Recognition) which is well regarded in the Computing industry, it is highly credible and intended for a professional audience, therefore uses very complicated terminology ideal for those with a good understanding of neural networks. The article is useful for our research topic as Dosovitiskiy et al. go in to a lot of detail when describing how they optimised their training to create truly unique data. In addition the concept of a neural network generalising images could be something that we further research as it is relatively simple, yet has a wide potential for future applications that are beyond the use of chairs. The main limitation of this article is that, although it uses a neural network, it does not specifically focus on a General Adversarial Networks so we would have to adapt some of their ideas when used in our own work.

\paragraph{}
We weren't sold on chairs, we looked for more inspiration. This article\cite{faces} by Gauthier evaluated the use of GANs to generate faces from random noise with specific characteristics. The author used his own results to examine the likelihood of producing real world faces from generative models as well as testing how he could control facial attributes through different inputs. Gauthier's research focused on breaking down the process of making his GAN. Furthermore, he recorded the changes he attempted to make using external input data and the effect they produce on the results. Due to the author being an undergrad student you might expect less depth of understanding. However, this is not visible and does not take away from the complexity. In addition, Gauthier has been well recognised at Stanford for his work which shows a high level of credibility. The article was made as a school project hence it was meant for an audience with a high level of understanding of machine learning, yet it still explains concepts in a comprehensible way. This article will be very useful for our research topic as it will help us when creating our own GAN and may give us guidance for generating faces or images. One limitation of the article is that it doesn't go into extensive detail on how they could explore their findings further, however, what he has provided is a good starting platform we can start from and use our own ideas with. Thus, this article is likely to be a great asset to our work for both our theoretical understanding as well as to help with our own GAN demonstration.

\subsection{Conclusion}
By considering a wide range of literature, we have developed a much deeper understanding on GANs and how they work at a deep, mathematical level. We have also explored a wide array of potential use cases of GANs that have already been implemented. This allowed us to see what kinds of things are possible going forwards and help us to create a novel use case. It also helped us realise that implementing joke generation with a GAN would be very difficult and thus we are choosing to go down a more image processing based route going forward.

\bibliography{bib}
\bibliographystyle{ieeetr}

\end{document}
